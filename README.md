# Amazon ML Challenge 2025 â€“ Smart Product Pricing Solution

# Team Optimizers

Team Members
1. Sahil Burnwal (Team Lead)
2. Sudhanshu Anand
3. Gagan C
4. Aditya Mohan Singh

Competition Platform: Unstop
Submission Date: October 13, 2025
Rank: Under 1000 among 82000 teams 

ğŸ“Œ Problem Statement

Predict product prices accurately using multimodal data (text + images) for Amazon-like product listings.
The evaluation metric is SMAPE, emphasizing robustness across low-, medium-, and high-priced products.


ğŸš€ Executive Summary

We propose a multimodal deep learning solution that fuses textual, visual, and engineered features to predict product prices.
Our final system uses:
1. TF-IDF + SVD for structured text understanding
2. ResNet50 image embeddings + PCA for visual signals
3. A 5-layer feed-forward neural network
4. A custom SMAPE-optimized hybrid loss function

ğŸ† Final Result

1. Cross-Validation SMAPE: 48.40
2. Relative improvement: ~11% over baseline
3. Low fold variance: Â±0.30 â†’ stable generalization

ğŸ§© Methodology Overview
ğŸ” Key Data Observations

1. Price range: $0.13 â€“ $2,796 â†’ log transformation required
2. ~38% products priced below $10 â†’ needs weighted learning
3. Pack size & quantity strongly affect price
4. Premium keywords (organic, imported, artisan) matter
5. Category-based price tiers exist (wine, cheese vs water, powder)

ğŸ—ï¸ System Architecture

Input Features (220)
â”‚
â”œâ”€â”€ Text Features (115)
â”‚   â”œâ”€â”€ Name TF-IDF + SVD (42)
â”‚   â”œâ”€â”€ Bullet TF-IDF + SVD (55)
â”‚   â””â”€â”€ Char n-grams + SVD (18)
â”‚
â”œâ”€â”€ Engineered Features (34)
â”‚   â”œâ”€â”€ Size / Pack / Volume (12)
â”‚   â”œâ”€â”€ Premium Indicators (6)
â”‚   â”œâ”€â”€ Category & Brand Encodings (2)
â”‚   â”œâ”€â”€ Text Statistics (7)
â”‚   â””â”€â”€ Interaction Terms (7)
â”‚
â”œâ”€â”€ Image Features (71)
â”‚   â”œâ”€â”€ ResNet50 â†’ PCA (65)
â”‚   â””â”€â”€ Image-Text Interactions (6)
â”‚
â–¼
BatchNorm â†’ Dropout
â–¼
FC Layers (384 â†’ 256 â†’ 128 â†’ 64 â†’ 32)
â–¼
Output: Price Prediction


ğŸ§  Feature Engineering
1ï¸âƒ£ Size & Quantity Features (Most Important)
a. Unit-normalized size (oz)
b. Pack count detection
c. Total volume (size Ã— pack)
d. Log & sqrt transformations
e. Binary flags (has_size, is_bulk)

2ï¸âƒ£ Premium & Quality Indicators
a. Ultra-premium: imported, artisan, handcrafted
b. Premium: organic, gourmet
c. Quality: natural, authentic
d. Weighted premium score

3ï¸âƒ£ Category & Brand Encoding
a. Rule-based category detection
b. Bayesian target encoding (m=10 smoothing)

4ï¸âƒ£ Interaction Features
a. size Ã— premium score
b. pack count Ã— premium
c. brand Ã— category
d. image Ã— text embeddings


ğŸ–¼ï¸ Image Processing Pipeline
1. Image download with retry & backoff
2. Resize â†’ 224Ã—224
3. Pretrained ResNet50 (no classifier)
4. PCA: 2048 â†’ 65 dimensions
5. Missing/broken images â†’ zero vector fallback

ğŸ‹ï¸ Model Training
ğŸ”§ Optimization Setup
1. Optimizer: AdamW
2. Learning Rate: 0.0008
3. Weight Decay: 0.0075
4. Batch Size: 384
5. Epochs: up to 200
6. Early Stopping: patience = 30
7. Scheduler: CosineAnnealingWarmRestarts
8. Target Transform: log1p(price)


ğŸ“ Custom Loss Function (Core Innovation)
Total Loss =
0.20 Ã— Weighted MSE
+ 0.20 Ã— Huber Loss
+ 0.60 Ã— SMAPE Loss

Why?
1. Directly optimizes competition metric
2. Handles outliers
3. Emphasizes low-price accuracy


ğŸ“Š Model Performance
Overall Metrics
Metric	Value
SMAPE	  48.40
RMSE	  $26.61
MAE	    $10.85
RÂ²	    0.364
MAPE	  66.15%

Price-Range Breakdown
PriceRange	  SMAPE	  MAE	  % Data
$0â€“$10	      51.60	  $4.26	  38%
$10â€“$20	      33.98	  $4.82	  26%
$20â€“$50	      50.36	  $12.25	  25%
>$50	        67.04	  $45.17	  11%

ğŸ§ª Ablation Study
Removed Component	    SMAPE
Full Model	          48.40
â€“ Size Features	      53.50
â€“ Target Encoding	    52.60
â€“ Image Features	    52.20
â€“ Custom Loss	        51.10
â€“ Premium Features	  50.50

ğŸ“Œ Key Insight:
ğŸ‘‰ Size & pack information is the strongest price signal.


âš ï¸ Challenges Faced
1. âŒ Transformer models rejected (API dependency)
2. âŒ Regex-only extraction failed on inconsistent formats
3. âš ï¸ Image CDN throttling
4. âš ï¸ Category imbalance & rare expensive items

âœ… Solutions
1. TF-IDF + SVD over transformers
2. Manual rule-based extraction
3. PCA + batch processing
4. Bayesian smoothing & heavy regularization

ğŸ”® Future Improvements

1. Attention-based feature weighting
2. Price-bucketed models
3. Category-specific experts
4. Vision Transformers (ViT)
5. Multi-task learning (price + category)
6. Graph-based brand/category modeling

ğŸ Conclusion
This project demonstrates that careful feature engineering + metric-aware optimization can outperform heavier models.
Our multimodal DNN achieves stable, competitive performance while remaining fully offline, reproducible, and efficient.


Note: The dataset used in this project is proprietary and governed by Amazon ML Challenge usage policies. As a result, raw data and derived features are not included in this repository. Only the complete training and feature engineering notebooks are shared to demonstrate methodology and implementation.
